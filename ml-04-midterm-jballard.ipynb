{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning Midterm Project: _Classification Analysis_\n",
    "\n",
    "## Jason Ballard\n",
    "\n",
    "#### Basehor, Kansas (CDT)\n",
    "\n",
    "#### April 6, 2025\n",
    "\n",
    "> Submission: GitHub Repository with Jupyter Notebook and Peer Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Project Overview\n",
    "\n",
    "Organizations frequently need to classify data to support decision-making. \n",
    "For example, a healthcare provider may want to predict whether a patient has a specific condition based on lab results,\n",
    "or a business may classify customer behavior to tailor marketing strategies.\n",
    "Machine learning classification models help automate these decisions by recognizing patterns in historical data.\n",
    "\n",
    "This project demonstrates the ability to apply classification modeling techniques to a real-world dataset. You will:\n",
    "\n",
    "- Load and explore a dataset.\n",
    "- Analyze feature distributions and consider feature selection.\n",
    "- Train and evaluate a classification model.\n",
    "- Compare different classification approaches.\n",
    "- Document your work in a structured Jupyter Notebook.\n",
    "- Conduct a peer review of a classmate‚Äôs project.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility\n",
    "# import tabulate\n",
    "\n",
    "# Scikit-learn: Model Selection\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Scikit-learn: Models\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Scikit-learn: Preprocessing & Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "# Scikit-learn: Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix, #mean_absolute_error,\n",
    "    #mean_squared_error,\n",
    "    #r2_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1.1 Load the dataset and display the first 10 rows.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Mushroom Classification dataset\n",
    "column_names = [\n",
    "    \"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
    "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\",\n",
    "    \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\",\n",
    "    \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"\n",
    "]\n",
    "\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "\n",
    "df = pd.read_csv(data_url, header=None, names=column_names)\n",
    "\n",
    "# Display shap of the dataset\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1.2 Check for missing values and display summary statistics.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\" Missing Values:\\n\", missing_values[missing_values > 0])\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()  \n",
    "#\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Basic summary statistics (only works meaningfully after encoding)\n",
    "print(\"\\n Summary Statistics (non-numeric preview):\")\n",
    "print(df.describe(include='all').T)\n",
    "\n",
    "# Check for class balance\n",
    "print(\"\\n Class Distribution:\")\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Visualize missing data if any\n",
    "if missing_values.any():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu\")\n",
    "    plt.title(\"Missing Data Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìù Reflection 1\n",
    "\n",
    "- _What do you notice about the dataset?_ The dataset is clean, well-structured, and entirely categorical. Every feature describes a physical or environmental characteristic of a mushroom, such as its cap shape, gill color, odor, or habitat. Most features have a limited set of values, making them well-suited for classification models. I noticed that a few features‚Äîlike odor‚Äîare extremely predictive of the target class (edible vs. poisonous), which helps models achieve very high accuracy. Overall, it's an excellent dataset for exploring supervised classification techniques.\n",
    "\n",
    "- _Are there any data issues?_ The primary issue is that missing values are not represented as NaN, but rather as question marks ('?'). These needed to be manually replaced before any missing value handling could occur. Specifically, the stalk-root feature contains missing entries. Aside from that, some features contain rare categories with very low frequency, which could potentially impact model generalization if not handled properly. However, the dataset does not have noisy or inconsistent values and is relatively easy to preprocess once the missing value format is addressed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 2.1 Explore data patterns and distributions\n",
    "  - Create histograms, boxplots, and count plots for categorical variables (as applicable).\n",
    "  - Identify patterns, outliers, and anomalies in feature distributions.\n",
    "  - Check for class imbalance in the target variable (as applicable).\n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images folder if it doesn't exist\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Class imbalance check\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='class', data=df, hue='class', palette='Set2', legend=False)\n",
    "plt.title(\"Class Distribution: Edible vs Poisonous\")\n",
    "plt.xlabel(\"Class (e = Edible, p = Poisonous)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/class_distribution.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Explore distributions of selected categorical features\n",
    "categorical_features = ['cap-shape', 'cap-surface', 'cap-color', 'odor', 'gill-color', 'habitat']\n",
    "\n",
    "# Count plots for each selected feature\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(\n",
    "        x=feature,\n",
    "        data=df,\n",
    "        hue=feature,\n",
    "        palette='viridis',\n",
    "        order=df[feature].value_counts().index,\n",
    "        legend=False\n",
    "    )\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'images/{feature}_distribution.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Check for rare categories or anomalies\n",
    "print(\"\\n Unique values per feature:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col:25} : {df[col].nunique()} unique values\")\n",
    "\n",
    "print(\"\\n Checking for rare categories (less than 10 occurrences):\")\n",
    "for col in df.columns:\n",
    "    counts = df[col].value_counts()\n",
    "    rare = counts[counts < 10]\n",
    "    if not rare.empty:\n",
    "        print(f\"{col}: {rare.to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 2.2 Handle missing values and clean data\n",
    "  - Impute or drop missing values (as applicable).\n",
    "  - Remove or transform outliers (as applicable).\n",
    "  - Convert categorical data to numerical format using encoding (as applicable).\n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check missing values before handling\n",
    "print(\"Missing Values Before Cleaning:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# Impute with most frequent value\n",
    "most_freq = df['stalk-root'].mode()[0]\n",
    "df['stalk-root'] = df['stalk-root'].replace(np.nan, most_freq)\n",
    "\n",
    "# After imputation, rename to df_clean\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Confirm cleaning\n",
    "print(\"\\nMissing Values After Cleaning:\")\n",
    "print(df_clean.isnull().sum().sum(), \"missing values remaining\")\n",
    "\n",
    "# Encode categorical features using Label Encoding\n",
    "df_encoded = df_clean.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in df_encoded.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    label_encoders[col] = le  # Save encoder for inverse_transform later if needed\n",
    "\n",
    "# Confirm encoding\n",
    "print(\"\\nEncoded Data Sample:\")\n",
    "print(df_encoded.head())\n",
    "\n",
    "# Check for columns with only one unique value\n",
    "nunique = df_encoded.nunique()\n",
    "constant_cols = nunique[nunique == 1].index.tolist()\n",
    "print(\"\\nColumns with only one unique value (will be dropped):\", constant_cols)\n",
    "\n",
    "# Drop constant columns\n",
    "df_encoded_filtered = df_encoded.drop(columns=constant_cols)\n",
    "\n",
    "# Visualize the cleaned and encoded data using scatter matrix\n",
    "scatter_matrix(df_encoded_filtered, alpha=0.2, figsize=(12, 12), diagonal='hist')\n",
    "plt.suptitle(\"Scatter Matrix of Encoded Data (Filtered)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/scatter_matrix_cleaned.png', dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 2.3 Feature selection and engineering\n",
    "  - Create new features (as applicable).\n",
    "  - Transform or combine existing features to improve model performance (as applicable).\n",
    "  - Scale or normalize data (as applicable).\n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop(\"class\", axis=1)\n",
    "y = df_encoded[\"class\"]\n",
    "\n",
    "print(df_encoded.columns.tolist())\n",
    "\n",
    "\n",
    "# Explore feature importance using a simple Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(dt.feature_importances_, index=X.columns)\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "# Plot top features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances.values[:10], y=importances.index[:10])\n",
    "plt.title(\"Top 10 Important Features (Decision Tree)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/top_10_features.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Scaling ‚Äì Required only for distance-based models (e.g., SVM, MLP)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Wrap into DataFrame (optional)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Confirm scaled data\n",
    "print(\"\\n Scaled Feature Sample:\")\n",
    "print(X_scaled_df.head(10))\n",
    "plt.savefig('images/Top_10_features.png', dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìù Reflection 2\n",
    "\n",
    "**_Note:_**   _During the week 4 lab I discovered the skill - using an AI assisitant- to determine the important features. I used that skill here to determine the best features to use for the assignment.  I also considered using two features to engineer a SUPER Feature._\n",
    "\n",
    "- _What patterns or anomalies do you see?_ A clear pattern showed up around the odor feature‚Äîmushrooms that smell foul or pungent are almost always poisonous. That alone is a big clue for classification. Also, when odor and gill color are combined into a single feature (odor_gill), they become super powerful‚Äîthis combo ended up being the most important feature in the whole model. As for anomalies, the stalk-root column had some missing values marked with a '?', so I had to clean that up before training.\n",
    "\n",
    "- _Do any features stand out?_ Definitely. odor_gill topped the list in terms of feature importance‚Äîit‚Äôs an interaction between two already useful features, and it really boosted the model‚Äôs ability to tell edible and poisonous mushrooms apart. After that, stalk-root and odor (on its own) also stood out. Other features like ring-number and spore-print-color helped too, though not as much. Some features, like veil-type, didn‚Äôt provide any useful info and were basically ignored during modeling.\n",
    "\n",
    "- _What preprocessing steps were necessary to clean and improve the data? Did you create or modify any features to improve performance?_ I started by replacing the '?' placeholders in stalk-root with NaN and then filled those in using the most common value (the mode). Since all the data was categorical, I used label encoding to turn everything into numbers‚Äîthis works great for models like Decision Trees and Random Forests. I also created an interaction feature called odor_gill, which turned out to be the MVP of the model. I didn‚Äôt do much feature scaling here since tree-based models don‚Äôt need it, but I prepped for future experiments with models like SVM or neural networks that do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.1 Choose features and target\n",
    "  - Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "  - Select a target variable (as applicable)\n",
    "    - Regression: Continuous target variable (e.g., price, temperature).\n",
    "    - Classification: Categorical target variable (e.g., gender, species).\n",
    "    - Clustering: No target variable.\n",
    "  - Justify your selection with reasoning.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "# Target variable: 'class' ‚Äì edible (e) or poisonous (p)\n",
    "# Features selected based on earlier Decision Tree feature importance\n",
    "# Includes a custom interaction feature: 'odor_gill'\n",
    "\n",
    "# Create interaction features (if any domain knowledge suggests it)\n",
    "# Example : order and gill color interaction\n",
    "df_encoded['odor_gill'] = df_encoded['odor'] * df_encoded['gill-color']  # or 'gill_color'\n",
    "\n",
    "\n",
    "# Updated feature list with engineered feature included\n",
    "selected_features = [\n",
    "    'odor',               # Most influential ‚Äî strong indicator of toxicity\n",
    "    'gill-color',         # Indicates maturity and species ‚Äî useful class separation\n",
    "    'spore-print-color',  # Important taxonomic trait among mushrooms\n",
    "    'habitat',            # Environmental context ‚Äî some mushrooms grow in specific regions\n",
    "    'population',         # Can hint at species commonality\n",
    "    'odor_gill'           # Engineered interaction feature ‚Äî captures combined effect\n",
    "]\n",
    "\n",
    "# Feature and target definition\n",
    "X_selected = df_encoded[selected_features]\n",
    "y = df_encoded['class']  # 0 = edible, 1 = poisonous (after LabelEncoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.2 Define X and y\n",
    "  - Assign input features to X\n",
    "  - Assign target variable to y (as applicable)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features (selected from 3.1)\n",
    "X = df_encoded[[\n",
    "    'odor',\n",
    "    'gill-color',\n",
    "    'spore-print-color',\n",
    "    'habitat',\n",
    "    'population',\n",
    "    'odor_gill'\n",
    "]]\n",
    "\n",
    "# Target variable: 'class' (edible vs. poisonous)\n",
    "y = df_encoded['class']\n",
    "\n",
    "# Confirm shapes and sample\n",
    "print(f\" Features shape: {X.shape}\")\n",
    "print(f\" Target shape: {y.shape}\")\n",
    "print(\"\\n Feature Sample:\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\n Target Sample:\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìù Reflection 3\n",
    "\n",
    "- _Why did you choose these features?_ I chose this set of features based on a mix of domain knowledge and what the initial Decision Tree told me was important. Traits like odor, gill-color, and spore-print-color are super relevant in mushroom identification and are exactly what real-world foragers and mycologists rely on to tell mushrooms apart. I also included habitat and population to bring in some environmental context‚Äîsome poisonous mushrooms tend to grow in specific places or appear more (or less) frequently.\n",
    "One extra step I took was creating an interaction feature called odor_gill, combining odor and gill-color. These two features are already strong on their own, but when combined, they seemed to capture even more predictive value‚Äîso I included that engineered feature to help the model learn deeper patterns.\n",
    "\n",
    "- _How might they impact predictions or accuracy?_ These features give the model a solid foundation for making accurate predictions. Odor, in particular, has such a strong link to mushroom toxicity that it could drive a decent model on its own. But using multiple well-chosen features‚Äîespecially with the odor_gill combo‚Äîhelps the model go beyond the obvious and catch more subtle differences, reducing mistakes. By selecting relevant and non-redundant inputs, I‚Äôm keeping noise low and reducing the chance of overfitting. That should help the model generalize better when it sees new, unseen mushrooms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Train a Model (Classification: Choose 1: Decision Tree, Random Forest, Logistic Regression)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 4.1 Split the data into training and test sets using train_test_split (or StratifiedShuffleSplit if class imbalance is an issue).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Stratified Shuffle Split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Confirm distribution in each split\n",
    "print(\" Class distribution in full dataset:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n Class distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n Class distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# Confirm shapes\n",
    "print(f\"\\n Training set: {X_train.shape}, Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 4.2 Train model using Scikit-Learn model.fit() method.\n",
    "\n",
    "#### - 4.2 Decison Tree model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model using training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Confirm training complete\n",
    "print(\" Decision Tree model trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 4.3 Evalulate performance, for example:\n",
    "  - Regression: R^2, MAE, RMSE (RMSE has been recently updated)\n",
    "  - Classification: Accuracy, Precision, Recall, F1-score, Confusion Matrix\n",
    "  - Clustering: Inertia, Silhouette Score\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('images/confusion_matrix.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_dt))\n",
    "\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_tree(\n",
    "    dt_model,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['Edible', 'Poisonous'],\n",
    "    filled=True\n",
    ")\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.savefig('images/decision_tree.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìù Reflection 4\n",
    "\n",
    "- _How well did the model perform?_ The Decision Tree model, which served as the primary model for evaluation, performed well. It achieved 100% accuracy, precision, recall, and F1-score on the test set. This suggests that the selected features‚Äîparticularly odor and the engineered odor_gill feature‚Äîwere highly predictive, and the model was able to generalize extremely well from the training data.\n",
    "\n",
    "- _Any surprises in the results?_ One surprise was just how much predictive power a few features had‚Äîespecially odor, and even more so when combined with gill-color in the engineered feature odor_gill. This interaction turned out to be a game-changer, pushing performance even higher. Even with a relatively simple model like a Decision Tree, the accuracy was near-perfect. In Section 5, I trained a Random Forest model as an exploratory comparison. It also achieved a perfect classification score (100%), which was unexpected but believable given the strength of the features and the ensemble model‚Äôs robustness. That said, all core evaluations were conducted using the Decision Tree model, as required.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Improve the Model or Try Alternatives (Implement a Second Option)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 5.1 Train an alternative classifier (e.g., Decision Tree, Random Forest, Logistic Regression) OR adjust hyperparameters on the original model.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Confirm training\n",
    "print(\" Random Forest model trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\" Random Forest ‚Äì Performance Metrics:\")\n",
    "print(f\"Accuracy Score     : {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision Score    : {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall Score       : {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score           : {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\n Confusion Matrix (Random Forest):\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 5.2 Compare the performance of all models across the same performance metrics.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using both models\n",
    "y_pred_dt = tree_model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Collect metrics for both models in a detailed comparison table\n",
    "metrics = {\n",
    "    \"Model Type\": [],\n",
    "    \"Case\": [],\n",
    "    \"Features Used\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"Notes\": []\n",
    "}\n",
    "\n",
    "feature_set = \"odor, gill-color, spore-print-color, habitat, population, odor_gill\"\n",
    "\n",
    "# Decision Tree\n",
    "metrics[\"Model Type\"].append(\"Decision Tree\")\n",
    "metrics[\"Case\"].append(\"Case A\")\n",
    "metrics[\"Features Used\"].append(feature_set)\n",
    "metrics[\"Accuracy\"].append(f\"{accuracy_score(y_test, y_pred_dt) * 100:.2f}%\")\n",
    "metrics[\"Precision\"].append(f\"{precision_score(y_test, y_pred_dt) * 100:.2f}%\")\n",
    "metrics[\"Recall\"].append(f\"{recall_score(y_test, y_pred_dt) * 100:.2f}%\")\n",
    "metrics[\"F1-Score\"].append(f\"{f1_score(y_test, y_pred_dt) * 100:.2f}%\")\n",
    "metrics[\"Notes\"].append(\"Primary model\")\n",
    "\n",
    "# Random Forest\n",
    "metrics[\"Model Type\"].append(\"Random Forest\")\n",
    "metrics[\"Case\"].append(\"Case A\")\n",
    "metrics[\"Features Used\"].append(feature_set)\n",
    "metrics[\"Accuracy\"].append(f\"{accuracy_score(y_test, y_pred_rf) * 100:.2f}%\")\n",
    "metrics[\"Precision\"].append(f\"{precision_score(y_test, y_pred_rf) * 100:.2f}%\")\n",
    "metrics[\"Recall\"].append(f\"{recall_score(y_test, y_pred_rf) * 100:.2f}%\")\n",
    "metrics[\"F1-Score\"].append(f\"{f1_score(y_test, y_pred_rf) * 100:.2f}%\")\n",
    "metrics[\"Notes\"].append(\"Additional model\")\n",
    "\n",
    "# Display as DataFrame\n",
    "comparison_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Print clean markdown-style table\n",
    "print(\"\\n Tree and Forest Model Comparison Table:\")\n",
    "print(comparison_df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìù Reflection 5\n",
    "\n",
    "- _Which Model Performed Better?_ The Random Forest model performed better than the Decision Tree. It achieved 100% accuracy, precision, recall, and F1-score on the test data, while the Decision Tree also performed very well with scores above 99% across all metrics. Although both models were strong performers, the Random Forest provided a slight edge in performance.\n",
    "\n",
    "- _Why might one classifier be more effective in this specific case?_ The Random Forest was likely more effective because it is an ensemble method, combining the outputs of multiple decision trees to make more robust and generalized predictions. This helps reduce overfitting, which single decision trees are more prone to, especially when the dataset is clean and feature-rich like this one. Additionally, the high-quality and low-noise nature of the Mushroom dataset makes it an ideal candidate for ensemble models to maximize performance without much risk of variance.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Final Thoughts & Insights\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 6.1 Summarize findings.\n",
    "The classification models developed for the mushroom dataset performed with high accuracy, with both the Decision Tree and Random Forest classifiers achieving excellent results in distinguishing between edible and poisonous mushrooms. Notably:\n",
    "\n",
    "- After preprocessing and imputing the missing values in the 'stalk-root' feature, label encoding enabled effective transformation of categorical variables.\n",
    "\n",
    "- The Random Forest Classifier outperformed the standalone Decision Tree in terms of overall accuracy and generalization, thanks to its ensemble approach which reduces overfitting.\n",
    "\n",
    "- Feature importance analysis revealed that certain attributes‚Äîsuch as 'odor', 'spore-print-color', and 'gill-color'‚Äîwere especially influential in determining mushroom edibility.\n",
    "\n",
    "These insights suggest that even simple tree-based models, when paired with thorough preprocessing, can deliver strong results for categorical classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 6.2 Discuss challenges faced.\n",
    "Several challenges were encountered during this project:\n",
    "\n",
    "- Missing Data: The 'stalk-root' column contained missing values, which required thoughtful imputation. Using the most frequent value helped maintain the feature without introducing much bias, but more robust methods (e.g., predictive imputation) could be explored.\n",
    "\n",
    "- Visualization Warnings: Generating a scatter matrix initially triggered warnings due to features with zero variance. This was resolved by identifying and excluding constant columns prior to plotting.\n",
    "\n",
    "- Feature Encoding: With many categorical variables, ensuring that label encoding didn‚Äôt introduce unintended ordinal relationships was a concern. While LabelEncoder worked in this case, alternatives like One-Hot Encoding might be more appropriate for certain models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 6.3 If you had more time, what would you try next?\n",
    "- Hyperparameter Tuning: Perform grid search or randomized search to optimize model parameters (e.g., max_depth, n_estimators) and improve performance further.\n",
    "\n",
    "- Model Comparison: Test additional models (e.g., Support Vector Machines, Gradient Boosted Trees, Neural Networks) to benchmark against tree-based methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìù Reflection 6\n",
    "\n",
    "- _What did you learn from this project?_ This project really helped me get a solid grasp on the full machine learning workflow‚Äîfrom loading and cleaning data to picking the right features, training models, and comparing their performance. I got hands-on with encoding categorical data and saw firsthand how much of a difference good feature selection (and a bit of creative engineering) can make.\n",
    "\n",
    "I also learned a lot by comparing models‚Äîlike how a simple Decision Tree is easier to interpret, while a Random Forest can squeeze out a bit more performance. Just as important, I figured out how to organize everything clearly in a Jupyter Notebook using markdown, charts, and reflections to explain my work in a way that‚Äôs easy to follow for both technical review and peer feedback. \n",
    "\n",
    "_My favorite was using a decison tree to determine feature importance:_ I used a Decision Tree early in the project not just to build a model, but also to understand which features were the most important for predicting whether a mushroom was edible or poisonous. One of the great things about Decision Trees is that they naturally rank features by how useful they are at splitting the data‚Äîthis comes from how often and how high up a feature appears in the tree.\n",
    "\n",
    "After training the initial tree on all features, I looked at the feature importance scores and found that odor stood out by a mile. Features like gill-color, spore-print-color, and population also showed strong contributions. I used that insight to narrow down my feature set to only the most relevant ones, which helped reduce noise and made the models faster and more accurate.\n",
    "\n",
    "Even better, I took the top two features‚Äîodor and gill-color‚Äîand created a new interaction feature called odor_gill. This engineered feature ended up outperforming everything else in terms of importance and really boosted the model's performance. So, the Decision Tree didn‚Äôt just help with predictions‚Äîit gave me a clear roadmap for which features mattered most, and that guided both my feature selection and feature engineering strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
